{% extends "base.html" %}
{% block title %}Methodology ‚Äî SpeechScore{% endblock %}

{% block content %}
<div class="fade-in max-w-4xl mx-auto">
    <h1 class="text-2xl font-bold text-white mb-2">Scoring Methodology</h1>
    <p class="text-gray-400 mb-8">How SpeechScore analyzes and grades speeches.</p>

    <!-- Table of Contents -->
    <nav class="bg-gray-900 border border-gray-800 rounded-xl p-5 mb-8">
        <h2 class="text-sm font-semibold text-gray-400 uppercase tracking-wide mb-3">Contents</h2>
        <ol class="space-y-1 text-sm">
            <li><a href="#pipeline" class="text-indigo-400 hover:text-indigo-300">1. Analysis Pipeline</a></li>
            <li><a href="#metrics" class="text-indigo-400 hover:text-indigo-300">2. Metrics Reference</a></li>
            <li><a href="#scoring" class="text-indigo-400 hover:text-indigo-300">3. How Scores Are Calculated</a></li>
            <li><a href="#profiles" class="text-indigo-400 hover:text-indigo-300">4. Scoring Profiles</a></li>
            <li><a href="#grades" class="text-indigo-400 hover:text-indigo-300">5. Grade Scale</a></li>
            <li><a href="#limitations" class="text-indigo-400 hover:text-indigo-300">6. Limitations &amp; Caveats</a></li>
        </ol>
    </nav>

    <!-- 1. Pipeline -->
    <section id="pipeline" class="mb-10">
        <h2 class="text-xl font-semibold text-white mb-4 flex items-center gap-2">
            <span class="text-indigo-400">1.</span> Analysis Pipeline
        </h2>
        <p class="text-gray-300 mb-4">Each uploaded audio file passes through a 10-module analysis pipeline:</p>
        <div class="grid sm:grid-cols-2 gap-3">
            {% set modules = [
                ("üé§", "Audio Quality Gate", "Estimates Signal-to-Noise Ratio (SNR) and assigns a quality level (HIGH / MEDIUM / LOW / UNUSABLE). Low-quality audio may produce unreliable metrics."),
                ("üìù", "Whisper STT", "OpenAI's Whisper large-v3 model transcribes speech to text with word-level timestamps. Runs locally on GPU (~25x realtime)."),
                ("üìä", "Core Text Analysis", "Lexical diversity (type-token ratio), syntactic complexity (parse tree depth), fluency score, discourse connectedness."),
                ("üìñ", "Advanced Text", "Readability scores (Flesch-Kincaid, Flesch Reading Ease), discourse structure, named entities, question density, perspective analysis."),
                ("üîÅ", "Rhetorical Analysis", "Detects anaphora, epistrophe, repeated phrases. Computes repetition score and rhythm regularity."),
                ("üòä", "Sentiment Analysis", "3-class sentiment (positive/negative/neutral) using a RoBERTa model fine-tuned on social media text. Includes per-segment emotional arc."),
                ("üîâ", "Core Audio Analysis", "Fundamental frequency (pitch), intensity, voice quality (jitter, shimmer, HNR), pause patterns, speaking rate (WPM)."),
                ("üéµ", "Advanced Audio", "Formant analysis (vowel space), pitch contour, uptalk detection, speaking rate variability, vocal fry ratio, emphasis patterns."),
                ("üìà", "Spectrogram", "Generates waveform, mel-spectrogram, and loudness visualizations via songsee."),
                ("‚ö°", "Scoring Engine", "Compares metrics against the database distribution. Assigns percentile-based scores with profile-specific weights."),
            ] %}
            {% for icon, name, desc in modules %}
            <div class="bg-gray-900 border border-gray-800 rounded-lg p-4">
                <div class="flex items-center gap-2 mb-1">
                    <span>{{ icon }}</span>
                    <span class="font-medium text-white text-sm">{{ name }}</span>
                </div>
                <p class="text-xs text-gray-400 leading-relaxed">{{ desc }}</p>
            </div>
            {% endfor %}
        </div>
    </section>

    <!-- 2. Metrics -->
    <section id="metrics" class="mb-10">
        <h2 class="text-xl font-semibold text-white mb-4 flex items-center gap-2">
            <span class="text-indigo-400">2.</span> Metrics Reference
        </h2>
        <p class="text-gray-300 mb-4">These are the core metrics extracted from each speech and used in scoring:</p>
        <div class="overflow-x-auto">
            <table class="w-full text-sm">
                <thead>
                    <tr class="border-b border-gray-800">
                        <th class="text-left py-2 px-3 text-gray-400 font-medium">Metric</th>
                        <th class="text-left py-2 px-3 text-gray-400 font-medium">Unit</th>
                        <th class="text-left py-2 px-3 text-gray-400 font-medium">Direction</th>
                        <th class="text-left py-2 px-3 text-gray-400 font-medium">Description</th>
                    </tr>
                </thead>
                <tbody>
                    {% for key, m in metric_defs.items() %}
                    <tr class="border-b border-gray-800/50 hover:bg-gray-900/50">
                        <td class="py-2.5 px-3 text-white font-medium">{{ m.label }}</td>
                        <td class="py-2.5 px-3 text-gray-400">{{ m.unit or '‚Äî' }}</td>
                        <td class="py-2.5 px-3">
                            {% if m.direction == 'higher_better' %}
                                <span class="text-green-400 text-xs">‚Üë higher = better</span>
                            {% elif m.direction == 'lower_better' %}
                                <span class="text-blue-400 text-xs">‚Üì lower = better</span>
                            {% elif m.direction == 'optimal' %}
                                <span class="text-amber-400 text-xs">‚äô optimal = {{ m.optimal }}</span>
                            {% else %}
                                <span class="text-gray-500 text-xs">‚Üï context-dependent</span>
                            {% endif %}
                        </td>
                        <td class="py-2.5 px-3 text-gray-400 text-xs leading-relaxed">{{ metric_info.get(m.label, metric_info.get(key, '')) }}</td>
                    </tr>
                    {% endfor %}
                </tbody>
            </table>
        </div>
    </section>

    <!-- 3. Scoring -->
    <section id="scoring" class="mb-10">
        <h2 class="text-xl font-semibold text-white mb-4 flex items-center gap-2">
            <span class="text-indigo-400">3.</span> How Scores Are Calculated
        </h2>

        <div class="space-y-4 text-gray-300 text-sm leading-relaxed">
            <div class="bg-gray-900 border border-gray-800 rounded-lg p-5">
                <h3 class="text-white font-medium mb-2">Step 1: Percentile Ranking</h3>
                <p>Each metric is compared against the distribution of <strong class="text-white">all {{ total_speeches }} speeches</strong> in the database. A speech's <em>percentile rank</em> tells you what percentage of speeches it exceeds for that metric.</p>
                <p class="mt-2 text-gray-400">Example: If a speech has 140 WPM and 70% of speeches are slower, its WPM percentile is 70.</p>
            </div>

            <div class="bg-gray-900 border border-gray-800 rounded-lg p-5">
                <h3 class="text-white font-medium mb-2">Step 2: Direction Adjustment</h3>
                <p>The percentile is converted to a score based on whether higher or lower values are desirable:</p>
                <ul class="mt-2 space-y-1 text-gray-400">
                    <li><span class="text-green-400">‚Üë Higher = better</span> (e.g., HNR, pitch variation): percentile rank <em>is</em> the score</li>
                    <li><span class="text-blue-400">‚Üì Lower = better</span> (e.g., jitter, vocal fry): score = 100 ‚àí percentile</li>
                    <li><span class="text-amber-400">‚äô Optimal target</span> (e.g., WPM=150): score follows a bell curve around the target ‚Äî farther away = lower score</li>
                </ul>
            </div>

            <div class="bg-gray-900 border border-gray-800 rounded-lg p-5">
                <h3 class="text-white font-medium mb-2">Step 3: Weighted Composite</h3>
                <p>Individual metric scores are combined using <strong class="text-white">profile-specific weights</strong>. Each scoring profile emphasizes different metrics (see below). The composite score is the weighted sum.</p>
            </div>

            <div class="bg-gray-900 border border-amber-500/30 rounded-lg p-5">
                <h3 class="text-amber-400 font-medium mb-2">‚ö†Ô∏è Known Limitation</h3>
                <p>The current scoring is <strong class="text-white">percentile-based</strong>, meaning scores reflect where a speech ranks <em>within this database</em>, not an absolute quality standard. With {{ total_speeches }} speeches of widely varying types (historical recordings, clinical samples, children's readings, trained orators), the percentiles can be misleading.</p>
                <p class="mt-2">For example, a speech at the 50th percentile gets a score of 50 (grade F), even though "average" in this database might represent perfectly good speech. We're working on absolute reference ranges to address this.</p>
            </div>
        </div>
    </section>

    <!-- 4. Profiles -->
    <section id="profiles" class="mb-10">
        <h2 class="text-xl font-semibold text-white mb-4 flex items-center gap-2">
            <span class="text-indigo-400">4.</span> Scoring Profiles
        </h2>
        <p class="text-gray-300 mb-4 text-sm">Each profile weights metrics differently to assess speeches for different purposes:</p>

        {% for name, profile in profiles.items() %}
        <div class="bg-gray-900 border border-gray-800 rounded-lg p-5 mb-4">
            <div class="flex items-center justify-between mb-3">
                <h3 class="text-white font-semibold capitalize">{{ name }}</h3>
                <span class="text-xs text-gray-500">Repetition: {{ profile.repetition_direction | replace('_', ' ') }}</span>
            </div>
            <p class="text-sm text-gray-400 mb-3">{{ profile.description }}</p>
            <div class="flex flex-wrap gap-2">
                {% for metric_key, weight in profile.weights | dictsort(by='value', reverse=true) %}
                {% set mdef = metric_defs.get(metric_key, {}) %}
                <span class="inline-flex items-center gap-1 px-2.5 py-1 rounded-full text-xs
                    {% if weight >= 0.15 %}bg-indigo-500/20 text-indigo-300 border border-indigo-500/30
                    {% elif weight >= 0.10 %}bg-blue-500/15 text-blue-300 border border-blue-500/20
                    {% elif weight >= 0.07 %}bg-gray-700/50 text-gray-300 border border-gray-600/30
                    {% else %}bg-gray-800/50 text-gray-500 border border-gray-700/30{% endif %}">
                    {{ mdef.get('label', metric_key) }}
                    <span class="font-mono font-bold">{{ "%.0f" | format(weight * 100) }}%</span>
                </span>
                {% endfor %}
            </div>
        </div>
        {% endfor %}
    </section>

    <!-- 5. Grade Scale -->
    <section id="grades" class="mb-10">
        <h2 class="text-xl font-semibold text-white mb-4 flex items-center gap-2">
            <span class="text-indigo-400">5.</span> Grade Scale
        </h2>
        <div class="bg-gray-900 border border-gray-800 rounded-lg p-5">
            <div class="grid grid-cols-5 sm:grid-cols-10 gap-2 text-center">
                {% set grades = [
                    ("A+", "97‚Äì100", "#22c55e"), ("A", "93‚Äì96", "#22c55e"), ("A-", "90‚Äì92", "#22c55e"),
                    ("B+", "87‚Äì89", "#3b82f6"), ("B", "83‚Äì86", "#3b82f6"), ("B-", "80‚Äì82", "#3b82f6"),
                    ("C+", "77‚Äì79", "#f59e0b"), ("C", "73‚Äì76", "#f59e0b"), ("C-", "70‚Äì72", "#f59e0b"),
                    ("D+", "67‚Äì69", "#f97316"), ("D", "63‚Äì66", "#f97316"), ("D-", "60‚Äì62", "#f97316"),
                    ("F", "0‚Äì59", "#ef4444"),
                ] %}
                {% for letter, range, color in grades %}
                <div class="py-2">
                    <div class="text-lg font-black" style="color: {{ color }}">{{ letter }}</div>
                    <div class="text-[10px] text-gray-500 mt-0.5">{{ range }}</div>
                </div>
                {% endfor %}
            </div>
            <p class="text-xs text-gray-500 mt-3 pt-3 border-t border-gray-800">
                Grade cutoffs follow standard academic thresholds. Because current scoring is percentile-based against {{ total_speeches }} diverse speeches, most scores cluster in the 40‚Äì70 range.
            </p>
        </div>
    </section>

    <!-- 6. Limitations -->
    <section id="limitations" class="mb-10">
        <h2 class="text-xl font-semibold text-white mb-4 flex items-center gap-2">
            <span class="text-indigo-400">6.</span> Limitations &amp; Caveats
        </h2>
        <div class="space-y-3 text-sm text-gray-300">
            <div class="bg-gray-900 border border-gray-800 rounded-lg p-4">
                <h3 class="text-white font-medium mb-1">üìä Small Database</h3>
                <p class="text-gray-400">With {{ total_speeches }} speeches, percentile distributions are not statistically robust. Adding or removing a few speeches can shift scores significantly.</p>
            </div>
            <div class="bg-gray-900 border border-gray-800 rounded-lg p-4">
                <h3 class="text-white font-medium mb-1">üéôÔ∏è Recording Quality Bias</h3>
                <p class="text-gray-400">Historical recordings (pre-digital) inherently score lower on audio metrics (HNR, SNR, jitter) due to recording technology, not speaker quality. A 1963 MLK speech will always have worse HNR than a 2020 podcast.</p>
            </div>
            <div class="bg-gray-900 border border-gray-800 rounded-lg p-4">
                <h3 class="text-white font-medium mb-1">üçéüçä Heterogeneous Comparisons</h3>
                <p class="text-gray-400">The database includes clinical speech samples, children's readings, casual conversation, and professional oratory. Comparing a dysarthric speaker against a TED talk conflates very different speech goals.</p>
            </div>
            <div class="bg-gray-900 border border-gray-800 rounded-lg p-4">
                <h3 class="text-white font-medium mb-1">üîÅ Repetition Paradox</h3>
                <p class="text-gray-400">Deliberate rhetorical repetition (MLK's "I have a dream") lowers lexical diversity scores. The system can't distinguish intentional craft from limited vocabulary without additional context.</p>
            </div>
            <div class="bg-gray-900 border border-gray-800 rounded-lg p-4">
                <h3 class="text-white font-medium mb-1">üîÆ Future: Absolute Reference Ranges</h3>
                <p class="text-gray-400">We plan to replace percentile-based scoring with absolute reference ranges grounded in speech science literature. This will produce stable, meaningful grades independent of database composition.</p>
            </div>
        </div>
    </section>

    <!-- DB Stats footer -->
    <div class="text-xs text-gray-600 border-t border-gray-800 pt-4 mt-8">
        Database: {{ total_speeches }} speeches ‚Ä¢ {{ total_analyses }} analyses ‚Ä¢ Scoring engine refreshes distributions every 5 minutes
    </div>
</div>
{% endblock %}
