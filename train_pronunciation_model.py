#!/usr/bin/env python3
"""
Train a pronunciation scoring model using pronunciation features and oratory scores.

Uses the pronunciation_training_data.csv generated by build_pronunciation_dataset.py.
Trains a simple regression model to predict oratory-like scores from pronunciation features.
"""

import json
import numpy as np
import pandas as pd
from pathlib import Path
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import Ridge, Lasso, ElasticNet
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_val_score, LeaveOneOut
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import joblib


# Features used for prediction
FEATURE_COLS = [
    'mean_word_confidence',
    'std_word_confidence',
    'problem_word_ratio',
    'pct_words_below_50',
    'pct_words_below_60',
    'pct_words_below_70',
    'pct_words_below_80',
    'pct_words_below_90',
    'words_per_minute',
    'mean_word_duration_ms',
]


def load_data(csv_path: str = 'pronunciation_training_data.csv') -> pd.DataFrame:
    """Load training data from CSV."""
    return pd.read_csv(csv_path)


def train_and_evaluate(df: pd.DataFrame, target_col: str = 'oratory_score'):
    """Train multiple models and evaluate using leave-one-out cross-validation."""
    
    # Extract features and target
    X = df[FEATURE_COLS].values
    y = df[target_col].values
    
    # Scale features
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # Define models to try
    models = {
        'Ridge': Ridge(alpha=1.0),
        'ElasticNet': ElasticNet(alpha=0.5, l1_ratio=0.5),
        'RandomForest': RandomForestRegressor(n_estimators=50, max_depth=3, random_state=42),
        'GradientBoosting': GradientBoostingRegressor(n_estimators=50, max_depth=2, random_state=42),
    }
    
    print("=" * 70)
    print("MODEL EVALUATION (Leave-One-Out Cross-Validation)")
    print("=" * 70)
    print(f"\nTraining samples: {len(df)}")
    print(f"Features: {len(FEATURE_COLS)}")
    print(f"Target: {target_col} (range: {y.min():.1f} - {y.max():.1f})")
    
    results = {}
    loo = LeaveOneOut()
    
    for name, model in models.items():
        # Leave-one-out predictions
        predictions = []
        actuals = []
        
        for train_idx, test_idx in loo.split(X_scaled):
            X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]
            y_train, y_test = y[train_idx], y[test_idx]
            
            model.fit(X_train, y_train)
            pred = model.predict(X_test)[0]
            predictions.append(pred)
            actuals.append(y_test[0])
        
        predictions = np.array(predictions)
        actuals = np.array(actuals)
        
        # Calculate metrics
        mse = mean_squared_error(actuals, predictions)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(actuals, predictions)
        r2 = r2_score(actuals, predictions)
        
        results[name] = {
            'RMSE': rmse,
            'MAE': mae,
            'R2': r2,
            'predictions': predictions,
            'actuals': actuals
        }
        
        print(f"\n{name}:")
        print(f"  RMSE: {rmse:.2f} (avg error in oratory score points)")
        print(f"  MAE:  {mae:.2f}")
        print(f"  RÂ²:   {r2:.3f}")
    
    # Find best model
    best_name = min(results.keys(), key=lambda k: results[k]['RMSE'])
    print(f"\n{'=' * 70}")
    print(f"BEST MODEL: {best_name} (RMSE: {results[best_name]['RMSE']:.2f})")
    print("=" * 70)
    
    return results, models, scaler, best_name


def train_final_model(df: pd.DataFrame, model_class, scaler):
    """Train final model on all data."""
    X = df[FEATURE_COLS].values
    y = df['oratory_score'].values
    
    X_scaled = scaler.transform(X)
    
    model = model_class
    model.fit(X_scaled, y)
    
    return model


def save_model(model, scaler, output_dir: str = '.'):
    """Save trained model and scaler."""
    output_dir = Path(output_dir)
    
    joblib.dump(model, output_dir / 'pronunciation_model.joblib')
    joblib.dump(scaler, output_dir / 'pronunciation_scaler.joblib')
    
    # Save feature names
    with open(output_dir / 'pronunciation_model_config.json', 'w') as f:
        json.dump({
            'features': FEATURE_COLS,
            'model_type': type(model).__name__,
            'description': 'Predicts oratory-style score from pronunciation features'
        }, f, indent=2)
    
    print(f"\nModel saved to {output_dir}")


def show_feature_importance(model, feature_names):
    """Show feature importance for tree-based models."""
    if hasattr(model, 'feature_importances_'):
        importances = model.feature_importances_
        indices = np.argsort(importances)[::-1]
        
        print("\n" + "=" * 70)
        print("FEATURE IMPORTANCE")
        print("=" * 70)
        for i in range(len(indices)):
            idx = indices[i]
            print(f"  {i+1}. {feature_names[idx]}: {importances[idx]:.3f}")
    elif hasattr(model, 'coef_'):
        coefs = np.abs(model.coef_)
        indices = np.argsort(coefs)[::-1]
        
        print("\n" + "=" * 70)
        print("FEATURE COEFFICIENTS (absolute values)")
        print("=" * 70)
        for i in range(len(indices)):
            idx = indices[i]
            print(f"  {i+1}. {feature_names[idx]}: {model.coef_[idx]:+.3f}")


def main():
    # Load data
    df = load_data()
    
    if len(df) < 5:
        print("ERROR: Need at least 5 samples for training. Add more scored recordings.")
        return
    
    # Train and evaluate
    results, models, scaler, best_name = train_and_evaluate(df)
    
    # Train final model with best architecture
    best_model_class = models[best_name]
    final_model = train_final_model(df, best_model_class, scaler)
    
    # Show feature importance
    show_feature_importance(final_model, FEATURE_COLS)
    
    # Save model
    save_model(final_model, scaler)
    
    # Show sample predictions
    print("\n" + "=" * 70)
    print("SAMPLE PREDICTIONS vs ACTUAL")
    print("=" * 70)
    print(f"{'Title':<45} {'Actual':>8} {'Predicted':>10} {'Error':>8}")
    print("-" * 70)
    
    X = df[FEATURE_COLS].values
    X_scaled = scaler.transform(X)
    preds = final_model.predict(X_scaled)
    
    for i, row in df.iterrows():
        title = row['title'][:42] + '...' if len(row['title']) > 45 else row['title']
        actual = row['oratory_score']
        pred = preds[i]
        error = pred - actual
        print(f"{title:<45} {actual:>8.1f} {pred:>10.1f} {error:>+8.1f}")


if __name__ == '__main__':
    main()
